{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RWz9QQyIgIs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from google.cloud import bigquery\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings ('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Отправка в BQ Raw Data (generated)"
      ],
      "metadata": {
        "id": "CtG5sYbzfU67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_excel('dataset.xlsx', usecols = ['location', 'sales', 'date'])"
      ],
      "metadata": {
        "id": "5WAr4BNTJQjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw['months_cyrilc'] = [re.findall('[\\u0401\\u0451\\u0410-\\u044f]+', i) for i in raw['date']]\n",
        "\n",
        "for i in range(len(raw)):\n",
        "    raw['months_cyrilc'][i] = raw['months_cyrilc'][i][0]\n",
        "\n",
        "mapping = dict({\"января\": 1,\n",
        "           \"февраля\": 2,\n",
        "           \"марта\": 3,\n",
        "           \"апреля\": 4,\n",
        "           \"мая\": 5,\n",
        "           \"июня\": 6,\n",
        "           \"июля\": 7,\n",
        "           \"августа\": 8,\n",
        "           \"сентября\": 9,\n",
        "           \"октября\": 10,\n",
        "           \"ноября\": 11,\n",
        "           \"декабря\": 12})\n",
        "\n",
        "raw['months_num'] = raw['months_cyrilc'].map(mapping)\n",
        "\n",
        "raw['date_adj'] = 0\n",
        "for i in range(len(raw)):\n",
        "    raw['date_adj'][i] = raw['date'][i].split()[2]+'/'+raw['months_num'][i].astype(str)+'/'+raw['date'][i].split()[0]\n",
        "\n",
        "raw['date_adj'] = pd.to_datetime(raw['date_adj'], format= \"mixed\")\n",
        "raw = raw.drop({'date', 'months_cyrilc', 'months_num'}, axis = 1)\n",
        "\n",
        "raw['sales'] = [re.sub('\\s+', '', i) for i in raw['sales']]\n",
        "raw['sales'] = raw['sales'].astype('int32')\n"
      ],
      "metadata": {
        "id": "ak1QYBa_KgEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset with Table name variable\n",
        "BqDatasetwithtable='Seasonality.Raw_data'\n",
        "#BQproject name variable\n",
        "BqProject='spartan-thunder-311714'\n",
        "# pandas-gbq method to load data\n",
        "# append data if data table exists in BQ project\n",
        "# set chunk size of records to be inserted\n",
        "raw.to_gbq(BqDatasetwithtable, BqProject, chunksize=20000, if_exists= 'replace') #'append' )"
      ],
      "metadata": {
        "id": "py0Z-_LIKgwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Получение из BQ Raw Data для обработки и насыщения"
      ],
      "metadata": {
        "id": "zqNsidgvfaSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = 'spartan-thunder-311714' # Change to your project.\n",
        "REGION = 'US'"
      ],
      "metadata": {
        "id": "cB9whAH2LKse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery df --project $PROJECT_ID\n",
        "\n",
        "SELECT\n",
        "    *\n",
        "FROM\n",
        "  `spartan-thunder-311714.Seasonality.Raw_data`"
      ],
      "metadata": {
        "id": "-_dC57UiLvlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df.groupby(['location'])['sales'].quantile(0.25)\n",
        "Q3 = df.groupby(['location'])['sales'].quantile(0.75)\n",
        "IQR = Q3-Q1\n",
        "\n",
        "df['month'] = df['date_adj'].dt.month\n",
        "for l in IQR.index.tolist():\n",
        "  # Calculate the lower and upper bounds for the current location 'l'\n",
        "  lower_bound = Q1[l] - 1.5 * IQR[l]\n",
        "  upper_bound = Q3[l] + 1.5 * IQR[l]\n",
        "\n",
        "  df.loc[df['location'] == l, 'Sales adjusting 1 step'] = np.where((df.loc[df['location'] == l, 'sales'] < lower_bound) | \\\n",
        "                              (df.loc[df['location'] == l, 'sales'] > upper_bound),\n",
        "                              df.loc[df['location'] == l].groupby(['month'])['sales'].transform(lambda x: x.median()),\n",
        "                              df.loc[df['location'] == l, 'sales'])\n",
        "\n",
        "df['year'] = df['date_adj'].dt.year\n",
        "df['variance'] = df.groupby(['location', 'year'])['Sales adjusting 1 step'].transform(lambda x: x.std() / x.mean())\n",
        "\n",
        "df['_avg_within_month_indx'] = df.groupby(['month', 'location'])['Sales adjusting 1 step'].transform('mean')\n",
        "df['Sales adjusting step 2'] = np.where((df['variance']>0.25) & (abs(df['Sales adjusting 1 step']/df['_avg_within_month_indx']-1)>=0.25),\n",
        "                                          df['_avg_within_month_indx'],\n",
        "                                          df['Sales adjusting 1 step'])\n",
        "\n",
        "\n",
        "df= df.sort_values(by = ['location', 'date_adj'], ascending = True)\n",
        "min_year = df['year'].min()\n",
        "df['Sales CumSum 12M'] = df.groupby(['location'])['Sales adjusting step 2'].transform(lambda x: x.rolling(window = 12).sum())\n",
        "df['Sales CumSum 12M'] = np.where(df['year']==min_year, df['Sales CumSum 12M'].fillna(df[df['year']==min_year].groupby(['location'])['Sales CumSum 12M'].transform('max')), df['Sales CumSum 12M'])\n",
        "\n",
        "df['Sales Moving Average'] = round(df['Sales CumSum 12M'] /12,0)\n",
        "df['Sales Moving Avg Smoothed'] = round(df.groupby(['location'])['Sales Moving Average'].transform(lambda x: x.rolling(2, min_periods = 1).mean()),0)\n",
        "df['Seasonal component'] = np.where(df['Sales Moving Avg Smoothed'].notna(), df['Sales adjusting step 2']-df['Sales Moving Avg Smoothed'], np.nan)\n",
        "df['Avg Seasonal component'] = np.where(df['Sales Moving Avg Smoothed'].notna(), df.groupby(['location', 'month'])['Seasonal component'].transform('mean'), np.nan)\n",
        "\n",
        "avg = pd.pivot_table(df,\n",
        "                     #columns = ['month'],\n",
        "                     index = ['location','month'],\n",
        "                     values = ['Avg Seasonal component'],\n",
        "                     aggfunc = 'mean')\n",
        "avg = avg.reset_index().groupby(['location'])['Avg Seasonal component'].sum()/12\n",
        "avg = avg.reset_index().rename(columns = {\"Avg Seasonal component\": \"corr_coeff\"})\n",
        "\n",
        "df= pd.merge(df, avg, on = \"location\", how = \"left\")\n",
        "df['Avg Seasonal Component adjusted'] = df['Avg Seasonal component'] - df['corr_coeff']\n",
        "\n",
        "df['Sales MovAvg Smoothed 12M'] = round(df.groupby(['location', 'month'])['Sales Moving Avg Smoothed'].transform('mean'),0)\n",
        "df['Sales MovAvg Smoothed 12M w SeasComp'] = df['Sales MovAvg Smoothed 12M'] + df['Avg Seasonal Component adjusted']\n",
        "df['max seas comp'] = df.groupby(['location'])['Avg Seasonal Component adjusted'].transform('max')\n",
        "df['Season months'] =np.where(df['Avg Seasonal Component adjusted']>=df['max seas comp']*0.5, 1, np.nan)\n",
        "#т.к. привели сезон.компон. и сглаженн.скользящую ср.продаж к средним по индексу месяца, то по умолчанию рассматривается 1 год. Поэтому нужно явно указать год, например, 2023.\n",
        "# максимальная сезон.комп - как кульминац.сезона"
      ],
      "metadata": {
        "id": "nlIiGJoqJo2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_cols = {}\n",
        "for col in df.columns:\n",
        "    new_name = re.sub('\\s+', '_',col)\n",
        "    #new_cols.append(col+\":\"+new_name)\n",
        "    new_cols.update({\n",
        "        col: new_name\n",
        "    })\n",
        "df.rename(columns = new_cols, inplace=True)"
      ],
      "metadata": {
        "id": "_3YgItDmNwi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Отправка в BQ очищенных и обогащенных данных"
      ],
      "metadata": {
        "id": "TJV5q6rR8YsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset with Table name variable\n",
        "BqDatasetwithtable='Seasonality.Enriched_raw_data'\n",
        "#BQproject name variable\n",
        "BqProject='spartan-thunder-311714'\n",
        "# pandas-gbq method to load data\n",
        "# append data if data table exists in BQ project\n",
        "# set chunk size of records to be inserted\n",
        "df.to_gbq(BqDatasetwithtable, BqProject, chunksize=20000, if_exists= 'replace') #'append' )"
      ],
      "metadata": {
        "id": "MBUDQ3is8YIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### создание summary в BQ через Python + var : создание summary в Superset"
      ],
      "metadata": {
        "id": "qm7MJZ_88a2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = 'spartan-thunder-311714' # Change to your project.\n",
        "REGION = 'US'"
      ],
      "metadata": {
        "id": "y4nI06iTKATA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%bigquery  --project $PROJECT_ID\n",
        "\n",
        "CREATE OR REPLACE VIEW Seasonality.Summary_python AS (\n",
        "select\n",
        "location,\n",
        "max(case when `Season_months` = 1 then `Avg_Seasonal_Component_adjusted` else null end) as max_season_comp,\n",
        "sum(case when `Season_months` = 1 then `Season_months` else null end) as season_months,\n",
        "min(case when `Season_months` = 1 then `month` else null end) as season_start_month,\n",
        "avg(case when `Season_months` = 1 then `Avg_Seasonal_Component_adjusted` else null end) as average_season_comp,\n",
        "NTILE(5) over (ORDER BY avg(case when `Season_months` = 1 then `Avg_Seasonal_Component_adjusted` else null end) desc) as `Group`,\n",
        "(avg(case when `Season_months` = 1 then `Sales_MovAvg_Smoothed_12M_w_SeasComp` else null end)/avg(case when `Season_months` is null then `Sales_MovAvg_Smoothed_12M_w_SeasComp` else null end))-1 as `Season_vs_NotSeason`\n",
        "from `spartan-thunder-311714.Seasonality.Enriched_raw_data`\n",
        "where  `year` = 2023\n",
        "group by 1);"
      ],
      "metadata": {
        "id": "dW9ITSj_J_WM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}